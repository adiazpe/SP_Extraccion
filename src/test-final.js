require('dotenv').config();
const { getAccessToken, getEmailsFromAPI, getTotalEmails } = require('./connections/sendpulse');
const { pool } = require('./connections/database');
const DatabaseService = require('./services/queries');

const testfinal = async () => {
    const startTime = performance.now();
    let extractionId;
    let batchCount = 0;
    let insertadosExitosos = 0;
    let actualizadosExitosos = 0;
    let sinCambios = 0;
    const TOKEN_REFRESH_INTERVAL = 50 * 60 * 1000;
    let lastTokenTime = Date.now();

    try {
        let tokenData = await getAccessToken();
        const batchSize = 100;
        let currentOffset = 0;
        let totalRegistros = 0;
        const startDate = '2024-12-02 00:00:00';
        const endDate = '2024-12-11 23:59:59';

        // Obtener total esperado
        const dateParams = {
            from: startDate,
            to: endDate
        };
        const totalExpected = await getTotalEmails(tokenData, dateParams);
        console.log(`üìä Total de registros esperados: ${totalExpected}`);

        // Crear registro de extracci√≥n con total esperado
        extractionId = await DatabaseService.createExtractionRecord(startDate, endDate, totalExpected);

        // Actualizar offset inicial con total esperado
        await DatabaseService.updateControlOffset(currentOffset, totalRegistros, totalExpected);

        while (totalRegistros < totalExpected) {
            if (Date.now() - lastTokenTime > TOKEN_REFRESH_INTERVAL) {
                tokenData = await getAccessToken();
                lastTokenTime = Date.now();
            }

            batchCount++;
            const startBatchTotal = process.hrtime(); // Iniciamos medici√≥n total del batch

            const params = {
                limit: batchSize,
                offset: currentOffset,
                from: startDate,
                to: endDate
            };

            const response = await getEmailsFromAPI(tokenData, params);
            const emails = response.data;

            //Nuevo proceso por batches usando los hashes
            if (emails && emails.length > 0) {
                console.log(`\nüì¶ Batch #${batchCount}:`);
                console.log(`üì• Registros en este batch: ${emails.length}`);
                await pool.query('START TRANSACTION');
                try {
                    const batchResult = await DatabaseService.processEmailBatch(emails, { startDate, endDate });
            
                    // Actualizar contadores con los resultados de la funci√≥n
                    insertadosExitosos += batchResult.new;
                    actualizadosExitosos += batchResult.updated;
                    totalRegistros += emails.length;
            
                    currentOffset += batchSize;

                    console.log(`‚ú® Nuevos: ${batchResult.new}`);
                    console.log(`üîÑ Actualizados: ${batchResult.updated}`);
                    console.log(`‚è∏Ô∏è Sin cambios: ${emails.length - (batchResult.new + batchResult.updated)}`);

                    // Actualizar offset y progreso
                    await DatabaseService.updateControlOffset(currentOffset, totalRegistros, totalExpected);
                    
                    await pool.query('COMMIT');

                    const completionPercentage = ((totalRegistros / totalExpected) * 100).toFixed(2);
                    console.log(`üìà Progreso: ${completionPercentage}%`);
                    console.log(`üìä Total procesados: ${totalRegistros} de ${totalExpected}`);

                    const endBatchTotal = process.hrtime(startBatchTotal);
                    const batchTotalTime = (endBatchTotal[0] * 1000 + endBatchTotal[1] / 1000000).toFixed(2);
                    console.log(`‚è±Ô∏è Tiempo total del batch: ${batchTotalTime}ms`);

                    // Validaci√≥n de batch incompleto
                    if (emails.length < batchSize) {
                        console.log('üì¶ Batch incompleto detectado, finalizando proceso');
                        break;
                    }
                } catch (error) {
                    await pool.query('ROLLBACK');
                    console.error('‚ùå Error en el batch:', error);
                    throw error;
                }
            } else {
                console.log('‚ùå No hay m√°s registros para procesar');
                break;
            }

            if (batchCount % 50 === 0) {
                console.log('\nüßπ Ejecutando limpieza de memoria');
                global.gc && global.gc();
            }
        }

        const endTime = performance.now();
        const totalSeconds = ((endTime - startTime) / 1000).toFixed(2);

        // Actualizar historial de extracci√≥n
        await DatabaseService.updateExtractionHistory(extractionId, {
            totalRegistros,
            insertadosExitosos,
            actualizadosExitosos,
            sinCambios,
            totalBatches: batchCount,
            lastOffset: currentOffset,
            executionTime: totalSeconds
        });

        // Resumen final
        console.log(`\nüéâ Proceso completado:`);
        console.log(`üìä Total registros procesados: ${totalRegistros}`);
        console.log(`üì• Total registros nuevos: ${insertadosExitosos}`);
        console.log(`üîÑ Total registros actualizados: ${actualizadosExitosos}`);
        console.log(`‚è∏Ô∏è Total registros sin cambios: ${sinCambios}`);
        console.log(`üì¶ Total batches: ${batchCount}`);
        console.log(`‚è±Ô∏è Tiempo total: ${totalSeconds} segundos`);
        console.log(`‚ö° Promedio por batch: ${(totalSeconds/batchCount).toFixed(2)} segundos`);

    } catch (error) {
        if (extractionId) {
            await DatabaseService.updateExtractionError(extractionId, error);
        }
        console.error('‚ùå Error:', error);
    } finally {
        await pool.end();
    }
};

// Para ejecutar en segundo plano
if (require.main === module) {
    testfinal().catch(console.error);
}

module.exports = testfinal;